[{"title":"Mysql Online DDL 详解","url":"/blog/2022/07/12/online_ddl/","content":"<script src=\"/js/mermaid.full.min.js\"></script>\n\n# 背景\n在和DBA沟通前对alter table 不熟悉，导致沟通不顺畅。从本文可以了解到DDL的执行过程，评估执行DDL对线上的影响。\n# `ALTER TABLE`\n能够修改shechma的内容如下：\n* 添加或删除列(columns)\n* 创建或销毁索引(index)\n* 改变列的类型(type)\n* 重命名列或表名\n* 修改表的存储引擎(storage engine)或者备注(comment)\n详细：https://dev.mysql.com/doc/refman/5.7/en/alter-table.html\n\n# 新增列的DDL会阻塞DML\n列操作的DDL支持的一些行为，其中新增列「Adding a column」是支持In place， rebuild table，「某些条件下」允许并发DML，特别注意新增自增列并不知支持并发DML。因此，add column操作在某些条件下是会阻塞DML。[详细的材料](https://dev.mysql.com/doc/refman/5.7/en/innodb-online-ddl-operations.html#online-ddl-column-operations)\n![功能表格](https://github.com/maidongcao/img/blob/master/online_ddl/online_ddl_allow_table.png?raw=true)\n\n* 下边做个实验，观察新增列对DML的影响。实验参考：https://dev.mysql.com/doc/refman/5.7/en/innodb-online-ddl-performance.html\n\n    1. session1: 创建表，进行事务查后不提交事务，加MDL读锁\n    ```\n    mysql> CREATE TABLE t1 (c1 INT) ENGINE=InnoDB;\n    mysql> START TRANSACTION;\n    mysql> SELECT * FROM t1;\n    ```\n    \n    2. session2 ：给表格t1新增列x， 此时DDL会被阻塞，加MDL写锁\n    ```\n    mysql> ALTER TABLE t1 ADD COLUMN x INT, ALGORITHM=INPLACE, LOCK=NONE;\n    ```\n    \n    3. session3 ：查询表格的数据，语句也会被阻塞，加MDL读锁\n    ```\n    mysql> SELECT * FROM t1;\n    ```\n    \n    4. session4: 查询当前执行的线程；会看到阻塞的原因\n    ```\n    mysql> SHOW FULL PROCESSLIST;\n    ```\n    结果如图：\n![执行结果](https://github.com/maidongcao/img/blob/master/online_ddl/show_process_result.png?raw=true)\n* 结论\n    1. MDL写锁触发锁表，导致DDL和DML都会阻塞\n    2. DDL过程中会持有MDL写锁，导致锁表\n    3. DDL的执行时长决定了DML的阻塞时长，如果DDL执行时长，会阻塞后续的DML \n\n# 新增列DDL的执行过程\n在mysql 5.5 之前新增列「**copy方式：在服务器层执行**」需要锁表并且时间比较长，mysql5.6后 新增列支持**INPLACE方法「存储引擎层执行**」，大幅度缩短了锁表的时\n## COPY和INPLACE\n从mysql5.6开始使用online DDL对DDL的执行过程进行了优化，解决了早期版本MysqlDDL操作锁表的问题，能够保证DDL执行过程报纸读写，不影响数据库对外服务。\n* 5.7之前版本 Mysql执行DDL的主要算法\n间。\n1. COPY：\n* 主要步骤：\n    1. 创建与原表结构定义一致的临时表\n    2. 对原表加锁，不允许执行DML，但允许快照读\n    3. 在临时表执行DDL语句\n    4. 逐行拷贝原表数据到临时表\n    5. 原表和临时表进行RENAME操作，此时升级原表上的锁，不允许读写，直至完成RENAME。\n    \n* 总结：\n    1. 需要将数据从原表拷贝到临时表，这个过程颇为耗时\n    2. 整个过程大部分时间会锁住原表，导致DDL过程数据表无法提供服务\n2. INPLACE\nINPLACE「InnoDB fast index creation」5.5之前只限于二级索引的创建和删除。\n* 主要步骤：\n    1. 创建临时的frm文件；\n    2. 对原表加锁，不允许执行DML，但允许查询；\n    3. 根据聚集索引的顺序，构造新的索引项，按照顺序插入新索引页；\n    4. 升级原表上的锁，不允许读写操作；\n    5. 进行RENAME操作，替换原表的frm文件，完成DDL操作；\n* 总结：\n    1. DDL过程加锁的粒度比较小\n    2. 直接操作底层frm文件，不需要新建临时表拷贝数据\n\n3. COPY和INPLACE的区别\n     * COPY需要建立临时表，逐行拷贝数据到临时表，而INPLACE是通过修改底层文件来实现DDL\n     * INPLACE的持有锁时间更短，对DML的并发性更好些\n\n## online DDL 执行新增列过程\n**由于目前线上使用的mysql 5.7，存储引擎为InnoDb，以下内容都基于这个版本讨论。**\n参考文档：https://dev.mysql.com/doc/refman/5.7/en/innodb-online-ddl.html\n\n上一节，我们看到了INPLACE的核心思想是通过操作mysql文件，降低IO操作和锁的粒度来降低MDL对DML的影响。mysql 5.7 的新增列操作也是使用INPLACE实现类似的操作。\n\n### INPLACE 分类\n\n| INPLACE执行方式 |  描述|\n| --- | --- |\n| Rebuilds Table | 行记录格格式的修改，如字段的增、删、类型修改 |\n| No-Rebuilds Table | 不涉及行记录格式的修改，如索引删除、字段名修改 |\n\n### 新增列的Online DDL过程 \nOnline DDL主要有PREPARE(准备)、EXECUTE(执行)和COMMIT(提交)三个阶段，如下：\n\n1. PREPARE：此过程都是轻量操作，新增frm和ibd文件和一些初始化操作\n    *     **创建新的临时frm文件「表结构文件」**；\n    *     **持有EXCLUSIVE-MDL锁，禁止读写操作**；\n    *     根据ALTER类型，确定执行方式(copy,Online-Rebuilds,Online-No-Rebuilds)；\n    *      更新数据字典的内存对象；\n    *      分配row_log对象记录增量(Rebuilds需要)；\n    *      **生成新的临时ibd文件「数据文件」(Rebuilds需要)**。\n    \n2. EXECUTE：\n    *     **降级EXCLUSIVE-MDL锁，允许读写**；\n    *     **记录执行期间产生的DML增量到row_log中(Rebuilds需要)**；\n    *     扫描old_table的聚集索引中每一条记录record；\n    *     根据构造新表对应的索引项；\n    *     将构造的索引项插入sort_buffer块中；\n    *     将sort_buffer块插入到新的索引中；\n    *     **将row_log中的记录应用到新临时表中，应用到最后一个block**；\n\n3. COMMIT：\n    * **升级到EXECLUSIVE-MDL锁，禁止事务读写**；\n    * 重做row_log中最后一部分的增量；\n    * 提交事务，写InnoDB redo日志；\n    * 更新InnoDB的数据字典表；\n    * 修改统计信息；\n    * **RENAME临时的ibd和frm文件**；\n    * 执行变更完成。\n\n* 概括\nrow_log记录了DDL执行期间产生的DML操作，这保证了变更期间表的并发性，通过以上过程可以看出在EXECUTE(执行)阶段表允许读写操作，操作记录在row_log中，在最后阶段应用到新表当中，保证了数据的完整性。\n## 原生Online DDL的局限\n原生Online DDL 实际上是在存储引擎层执行的，对存储引擎的类型有一定的要求，并且目前并不是所有的DDL都执行oneline DDL。某些DDL不支持online DDL，会出现较大的代价。\n实际生产环境中，更多的是希望有一种方式能够适配所有存储引擎和DML和所有的DDL能够并发执行，所有业界一般是更多使用例如gh-host等中间件来实现服务器层的并发DDL。\n\n# gh-host执行DDL\n  由于原生online DDL支持的DDL有限「限制了存储引擎，DDL类型等」，所以业界一般使用的是gh-host工具「实现服务器层的DML和DDL并发，使用所有的DDL和存储引擎」执行DDL\n  ## 执行过程\n  ![gh-host](https://github.com/maidongcao/img/blob/master/online_ddl/gh-ost-general-flow.png?raw=true)\n      1. Gh-ost 在主库和从库建立临时表「ghost table」\n      2. Gh-ost 消费从库的binlog「公司内部消费的是主库的binlog」\n      3. 把binlog回放临时表，在此过程中也同时拷贝原表到从表「原生online dll是先全量拷贝再同步增量」\n      4. cut-over：临时表和原表切换「此才会有阻塞」\n  ## cut-over 阻塞过程\n  \n\n|  | clinet session 1 | gh-ost session 1 | clinet session 2 | gh-ost session 2 | clinet session 3 |\n| --- | --- | --- | --- | --- | --- |\n| Time 1 |  正常 DML |  |  |  |  |\n| Time 2 |  | 创建del表「回滚使用」锁原表锁del表| SELECT & DML 等待gh-ost session 1  |  |  |\n| Time 3 |  |  |  | 执行rename表交换 | SELECT & DML 等待gh-ost session 1 锁  |\n| Time 4 |  | 检测到gh-ost session 2 的rename sql，释放锁 | 等待锁 | 执行rename，完成表交换  | 等待锁 |\n| Time 5 |  |  | 正常执行 |  |  正常执行 |\n\n1. client session 1 执行DML，此时gh-ost尝试加表锁；如果client session 1的DML是大事务，会加锁等待，3s后未加锁成功，会DDL执行失败。\n2. 创建del表、锁原表和锁del表，这个步骤会加表锁\n3. 提交rename表操作和正常流量的DML都会等待步骤2的表锁\n4. 步骤2释放锁的时机是检测到gh-ost有提交rename sql。此时释放表锁，rename sql优先持有表锁执行rename 操作，完成表交换「执行时间很短」。\n5. 在步骤4「rename」执行过程中，其他的DML都在等待表锁，一旦rename完成，会继续获取锁继续执行DML操作\n\n  ## 总结\n  1. cut-over过程中，主要的耗时在gh-ost锁原表。此时如果正常的DML有大事务，会导致无法获取到表锁，导致失败\n  2. gh-ost获取表锁前有大事务，不会影响正常的DML。因为此时gh-ost未获取锁。\n  3. 一旦gh-ost获取表锁，后续的DML都会锁等待，直到rename「获取锁优先级最高」完成才执行\n# 总结\n1.  online DDL下进行新增列会存在短暂的锁表。对于大表的表记录修改，建议在低峰期操作。\n2.  执行DDL前，先评估下DDL可能对业务产生的影响，确认影响方案，和DBA确认阻塞的影响范围。\n3. 由于执行alter table 是需要拷贝数据的，建议多个alter table 合并成一条。\n4. 执行DDL前需要保证有足够的磁盘空间","tags":["mysql"],"categories":["mysql"]},{"title":"根节点和stw","url":"/blog/2021/07/30/gc root&stw/","content":"*  gc roots 有哪些？\n1. 全局引用（静态变量或者常量的引用）\n2. 执行上下文（局部变量表或者本地方法栈的变量表）\n3. 跨代引用的对象，老年代对新生代的引用，记录在RSET中。\n* 什么是stw（stop the world）\nstw指的是停顿所有的用户线程，然后进行进行可达性分析。\n* 什么情况下会出现stw\n1. 枚举根节点时 必须stw\n2. 整理内存碎片时 必须进行stw，也就是标记-整理算法必须stw\n* 可达性分析包含那几部分，哪些部分必须stw。\n可达性分析可以分为枚举根节点和查找引用链两个步骤。\n枚举根节点是可达性分析准确性的基础,枚举根节点必须准确，所以必须stw。\n查找引用链是耗时最长的操作，但是可以和用户线程并发执行，不需要stw。\n* rset是什么？\nrememberset 是一种用于记录从非收集区到收集区的指针集合的数据结构。\n* 卡表、卡页和remenberset的区别和联系。\n1. rset记录了非收集区到收集区的指针集合，也就是非收集区到收集区的引用关系。但是具体实现rset是依靠卡表。\n2. 一块内存可以分成若干个卡页，每一个卡页是否存在跨代引用，使用卡表来记录。如果存在跨代引用那么就是dirty。如图所示：\n![卡表和卡页对应关系](http://assets.processon.com/chart_image/61c4bb1c1e085364150a2a38.png)\n垃圾回收时，只要筛选出卡表中 dirty的元素 即可获取到哪些卡页包含跨代引用，把这些卡页放到gc roots 中进行扫描。\n* 卡表元素如何维护呢？何时变dirty，谁来把他们变dirty？\n* 什么是伪共享，卡表是如何解决伪共享问题？\ncpu的内存是以缓冲行为单位进行传输的，如果缓存行中多个数据频繁修改，会出现大量的缓冲回写，无效化和同步操作，导致效率变低。所以建议书写的代码具有局部性原理。\n卡表如果每次写操作都更新，那么就会面临伪共享问题。如果在每次将卡表变脏前，先检查卡表是否为脏，只有不为脏的卡表才更新，可以降低伪共享的问题。\n","tags":["java"],"categories":["编程语言"]},{"title":"redis持久化","url":"/blog/2021/07/26/redis_durability/","content":"<script src=\"/js/mermaid.full.min.js\"></script>\n## 持久化\n因为redis是内存数据库，一旦服务器进程退出，那么内存的数据将会销毁。为了保存redis的内存数据，就需要一种将内存落盘的持久化手段，服务器重启后能够加载落盘后的数据来恢复服务器的状态。\n持久化的方式有RDB[快照]和AOF[日志追加]两种。\n## RDB--快照文件(恢复时间快但丢失数据多)\n### 创建RDB文件--SAVE和BGSAVE\n1. 为了防止生成RDB过程中，写入的数据干扰RDB的生成。\n**SAVE 保存EDB过程会阻塞主进程，BGSAVE通过fork子进程，父进程正常工作。**\nbgsave命令的运作流程，如下所示。\n```mermaid\ngraph TD\nA[BGSAVE] -->|1| B(父进程)\nB --> H(有其他子进程正在执行 直接返回)\nB --> |2|C(fork 父进程会阻塞)\nC -->|3| D[响应其他命令]\nC -->E[子进程]\nE -->|4| F[生成RDB默认使用LZF进行压缩]\nE -->|5通知父进程| B\n```\nRDB文件可以落盘或者通过网络发生给其他节点进行复制。\n* 在执行BGSAVE期间，服务器处理SAVE，BGSAVE和REWRITEAOF的命令与平时不同\n    1. 执行BGSAVE期间，执行SAVE和BGSAVE是会被拒绝的。因为父进程和子进程之间存在竞争条件。\n    2. BGSAVE和REWRITEAOF的命令不能同时执行。如果BGSAVE先执行，那么REWRITEAOF会延时。放过来，BGSAVE会被拒绝。\n### 加载RDB文件\n服务器载入文件的流程，如下所示\n```mermaid\ngraph TD\nA[服务器启动] -->B[执行载入程序]\nB --> C{已开启AOF持久化功能}\nC -->|是| D[载入AOF]\nC -->|否| E[载入RDB文件]\n```\n### RDB的优缺点\n* 优点\n1.  RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照。非常适用于备份，全量复制等场景。把RDB文件拷贝到远程机器或者文件系统中（如hdfs），用于灾难恢复。\n2. Redis加载RDB恢复数据远远快于AOF的方式。\n* 缺点\n1. RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高。\n2.  RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问题。？？？ 有哪些格式\n## AOF--独立日志方式\nAOF（append only file）持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。主要解决数据持久化的实时性问题。\n### AOF的工作流程\nAOF的工作流程操作：命令写入（append）、文件同步（sync）、文件重写（rewrite）、重启加载。\n\n```mermaid\ngraph TD\nA[命令写入] -->|1apend:使用文本协议| B(AOF缓冲区)\nB --> |2sync| C[AOF文件]\nC --> |重写| C\nD[重启] --> |load| C\n```\n\n* 为什么命令写到AOF缓冲区，而不是直接写入到AOF文件?\n    1. Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。\n    2. 写入缓冲区，redis就可以提供多种同步磁盘策略，也就是落盘的方案选择可以有多种。\n* AOF缓冲区同步策略有哪些？\n    1. always: 命令写入缓冲区后，立马同步硬盘。\n    2. everysec: 每秒同步一次缓冲区。\n    3. no: 有操作系统策略进行同步。\n * 为什么需要重写？解决了什么问题？\n   AOF是通过保存写命令来记录数据库的状态，但是随着写入的命令增多，文件的体积就会越来越大。AOF文件过大会造成影响redis和宿主机的性能，并且过大的AOF文件还原需要的时间也就越多。重写通过构造某个时刻数据库的状态的写入语句来减少AOF的命令数目，从而实现压缩AOF的目的。\n * 重写的原理是什么？\n    AOF的重写**不是对旧的AOF文件进行读取、分析或者写入操作，而是通过读取当前数据库的状态来实现的。**\n    假如使用了3条命令分别写入了键为key的， value分别为a b c的list，AOF的重写就是读取当前数据库的状态，重写的命令为1条 写入 key a b c的命令。\n    总之，首先从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。\n  * redis是单线程的，AOF重写如何防止阻塞主进程呢？\n    AOF的重写是后台进行的。\n    1. 发起AOF重写时，会在父进程fork子进程来进行重写，同时创建AOF重写缓冲区。\n    2. 重写后的命令会写入AOF重写缓冲区。\n      \n```mermaid\nsequenceDiagram\n客户端->>命令处理器: 发送命令\n命令处理器-->>AOF缓冲区: 追加命令\n命令处理器-->>AOF重写缓冲区: 追加命令\n```\n    \n    3. 新写入的命令，父进程处理后，会同时写入AOF缓冲区和AOF重写缓冲区，防止重写AOF时，导致数据不一致的问题。\n    4. 但子进程完成AOF重写后，会向父进程发生信号。\n    5. 父进程此时会阻塞客户端的命令，来将重写后的AOF更替成就的AOF.首先将AOF重缓冲区写入新的AOF文件，然后将AOF进行改名并覆盖旧的AOF.\n## 主从复制\n使用A服务器的客户端输入:SLAVEOF B{IP:端口} 那么A就是变成B的从服务器，B的数据也会同步到A中。也就是主服务器B会同步数据给从服务器A。\n新版的主从复制包括完全重同步和部分重同步，旧版的主从复制只有完全重同步。\n  **旧版的主从复制，如果网络闪断会进行一次完全的同步，会消耗大量的资源，导致同步时间变长。**\n  完全重同步：主要用于初次进行主从复制或者长时间断联后重新同步。主服务生成RDB文件，同时将启动生成RDB文件后的命令写入缓冲区。RDB生成后发生给从服务器，等RDB被从服务器加载完后，再将缓冲区命令发给从服务器。\n  部分重同步:主要用于网络闪断的同步恢复。从服务断联后，重新连上到主服务，如果条件允许（数据偏移量相差在一定范围），主服务会把断联期间的数据发生给从服务进行同步。\n  * 完全重同步跟旧版的复制功能几乎一样，如图。\n  \n  \n```mermaid\nsequenceDiagram\n从服务器->>主服务器: 发送SYNC\n主服务器-->>从服务器: 发送RDB\n主服务器-->>从服务器: 发送缓冲区保持的所有命令\n```\n\n  * 部分重同步\n  部分重同步主要以3部分组件实现：\n        1. 主服务器和从服务器的复制偏移量，用于检查主从服务器是否一致，从服务器是每秒发生一次心跳给主服务器同步偏移量。\n    2. 主服务器的复制积压缓冲区（默认为1M），主服务器的每条写命令都会写入复制缓冲区和从服务器。\n    3. 服务器的运行ID。\n   * 部分重同步实现步骤：\n    1. 每次主服务器向从服务器发生写命令时，会同步数据偏移量，并把写命令写入复制积压缓冲区。\n    2. 从服务器断联后，一段时间重新连接上主服务器，会向主服务发生PSYNC并报告自己的数据偏移量。\n    3. 主服务器收到从服务器的偏移量，计算目前积压缓冲区的偏移能否可以完成从服务器的同步，如果不可以那么就会进行完全同步，如果可以，就把积压缓冲区的命令发送给从服务器。\n   4. 从服务同步完数据后，更新偏移量。\n### PSYNC的工作流程\n\n```mermaid\ngraph TD\nA[从服务器接到客户端发来的SLAVEOF命令] -->B{首次复制}\nB --> |Y|C[向主服务器发送PSYNC?-1]\nB --> |N|D[向主服务器发送PSYNC <RUNID> <OFFSET>]\nC -->E[主服务器返回+FULLRESYNC<RUNID><OFFSET>执行完全重同步]\nD --> F{主服务器返回+continue}\nF -->|N| E\nF -->|Y|G[执行部分重同步] \n```\n\n\n### 主从复制过程中对过期的键的处理    \n 主从服务过程过期键的处理有特别的方式。**注意从服务器是无法自行删除过期键的，必须由主服务器触发，其实从服务器触发了惰性删除也不会执行，这样为了保持主从的一致性**，以下讲述，生成和加载RDB和AOF过程的过期键处理方式。\n 1. 生成RDB--子进程进行\n    * redis会对数据库的键进行检查，过期键不会生成RDB\n  2. 载入RDB--是否容忍键检查的时间开销\n   * 如果是主服务加载RDB，那么会对键进行检查，过期键不会加载到RDB。\n   * 如果服务是从服务器，从服务器不管是否RDB是否有过期键，都会加载到武器。\n  3. 生成AOF--是否容忍键检查的时间开销\n   * 如果数据库中存在已经过期的键，但是未被惰性或定期删除，那么也会这些过期的键也会生成到AOF文件中。\n   * 如果键被过期了，且触发了删除操作，那么AOF也会追加删除命令。\n   4. AFO重写--子进程进行\n  *  AOF重写会校验过期的键，不会写入到重写的AOF中。\n总之, 主服务器生成或加载RDB时，会忽略过期的键，因为主服务是通过子进程生成RDB的，由生成方保证数据的最新对redis服务器影响最小，并且主服务加载RDB一般是服务启动时，可以检查键过期，导致等待时间长不会造成功能问题；从服务器为了提高RDB的加载效率，尽快地进行数据同步，例如长时间断联后，进行完成重同步不能等待太久，所有不会对键的过期进行检查，直接加载RDB。生成AOF的频率比极高，不允许频繁检查键是否过期，所有会直接加载数据库的数据。AOF重写是在子进程操作，对父进程影响小，而且是进行优化目录来重写的，所有允许进行检查键是否过期。\n  * 一言蔽之，**复制过程中，是否进行键检查，取决于操作是否在子进程进行， 是否能容忍长时间的检查操作。**\n","tags":["redis"],"categories":["redis"]},{"title":"指针和值","url":"/blog/2021/07/24/pointer_value/","content":"# 指针\n## 值和指针\n\n  * 值的声明直接写类型即可，如int\n  * 指针的声明需要在类型前加*，如 *int\n````\nvar v int = 1  // 开辟的一块空间，名字为v, 空间的值为1`\nvar p *int = &v  // 获取v的地址存到名为p的内存空间，*int 指向int类型的指针\n````\n\n![&和*的操作关系](http://assets.processon.com/chart_image/6016be58e401fd15813cfba8.png?_=1636815032732)\n## 指针操作\n* 操作符&(取址符) : 是返回该变量的内存地址\n* 操作符* (取值符) : 是返回该指针指向的变量的值, 同时也可以进行修改指针指向内存地址的值\n**取地址操作符&和取值操作符\\*是一对互补操作符**\n````\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc  TestGetAddAndVal(t *testing.T)  {\n\n    // 准备一个字符串类型\n    var house = \"Malibu Point 10880, 90265\"\n\n    // 对字符串取地址, ptr类型为*string\n    ptr := &house\n\n    // 打印ptr的类型\n    fmt.Printf(\"ptr type: %T\\n\", ptr)  // ptr type: *string\n\n    // 打印ptr的指针地址\n    fmt.Printf(\"address: %p\\n\", ptr) // address: 0xc0420401b0\n\n    // 对指针进行取值操作\n    value := *ptr\n\n    // 取值后的类型\n    fmt.Printf(\"value type: %T\\n\", value) // value type: string\n\n    // 指针取值后就是指向变量的值\n    fmt.Printf(\"value: %s\\n\", value) // value: Malibu Point 10880, 90265\n\n}\n````\n  \n## 指针细节\n### 指针赋值\n\n  go 的函数和接受者都只有值传递方式，不存在引用传递。指针传递也是传递指针的地址\n\n  以数值交换为例\n\n1. 使用多重赋值进行值交换\n```\npackage main\n\nimport \"fmt\"\n\nfunc swap(a, b int) {\n    b, a = a, b\n     fmt.Println(b, a)\n         fmt.Println(&b, &a) \n}\n\nfunc main() {\n    x, y := 1, 2\n    swap(x, y)\n    fmt.Println(x, y)\n}\n```\n2. 交换指针\n```\n\npackage main\n\nimport \"fmt\"\n\nfunc swap(a, b *int) {\n    b, a = a, b\n}\n\nfunc main() {\n    x, y := 1, 2\n    swap(&x, &y)\n    fmt.Println(x, y)\n}\n```\n## 接受者指针和值\n指针不仅可以作为函数的入参和返回值，也可以作为接受者\n接收者可以为指针和值，指针会拷贝指针地址给到接收者，值会重新拷贝值给到接收者\n```\npackage pointer\n\ntype Project struct {\n    Code int\n}\nfunc (p Project) printVal() {\n    // 拷贝一个新的Project给p，不省内存\n    fmt.Printf(\"p: type:%T, add:%p\\n\", p, &p) // 地址和origin 不一样\n}\nfunc (p *Project) printProinter() {\n    // 拷贝一个新的地址给p\n    fmt.Printf(\"p: type:%T, add:%p\\n\", p, p) // 地址和origin 一样\n}\nfunc TestReceiver(t *testing.T) {\n    p := Project{}\n    fmt.Printf(\"origin p: type:%T, add:%p\\n\", p, &p)\n    p.printVal()\n    p.printProinter()\n}\n```\n*  指针接收者节省内存，，结构体很大时，性能比较好，应用运行通过指针修改变量的场景\n* 值接收者可以实现每个接收者都是全新的拷贝，可以实现不可变型的变量，提高代码的安全性，但是占用内存比较高\n\n## 实现不可变型结构体\n由于go值传递的特性，通过设置接收者的可见性为包内，并且通过值作为接受者进行拷贝新的值来实现不可变。废话不多说，直接上代码\n```\n\n// 指针 -> 修改原来地址的值\n// 值 -> 没法修改原来地址的值\n// 不可变型: 值一旦被创建就无法被改变对象,修改通过生成一个新的对象来实现\ntype Person struct {\n    name           string // 包内可见，避免被修改\n}\nfunc (p Person) WithName(newname string) Person { // 拷贝新的结构体，返回新的结构体\n    p.name = newname\n    fmt.Printf(\"WithName p's add:%p\\n\", &p) // 打印地址 0xc000064540\n    return p\n}\nfunc (p Person) Name() string { // getter\n    return p.name\n}\n// 值接收者实现不可变型\nfunc TestImmutableForm(t *testing.T) {\n    me := Person{} // 默认初始化\n    fmt.Printf(\"me data:%+#v\\n\", me.Name())\n    fmt.Printf(\"add:%p, data:%+#v\\n\", &me, me) // 0xc0000644e0\n    m2 := me.WithName(\"Elliot\")\n    m2.Name()\n    fmt.Printf(\"m2 data:%+#v\\n\", m2.Name())\n}\n```","tags":["golang"],"categories":["编程语言"]},{"title":"线程安全与锁优化","url":"/blog/2020/07/04/lock/","content":"<script src=\"/js/mermaid.full.min.js\"></script>\n## 线程安全\n1. 线程安全概念：不管运行环境的调度或交替进行，最终的运行结果都是正确的。\n共享数据的线程安全从强到弱的分类：\n    * 不可变性：对象被构造出来后，内部的状态不会改变。基本数据类型；普通对象不会改变，或者状态被final修饰，如String，枚举类\n    * 绝对安全：不管运行环境如何，调用者不需要做额外的措施保护线程安全。\n    * 相对安全：一般意义上说的线程安全，对对象的单独操作是线程安全的。如线程安全类HashTable，Vector（不是任意环境下线程安全，利用多线程同时查询和删除，会出现线程不安全，需要额外的措施保证线程安全）\n    * 线程兼容：对象本身线程不安全，通过额外的措施可以保证线程安全。\n    * 线程对立: 无论使用任何措施都不能保证线程安全，例如suspend()和resume()【都不会释放锁，可能导致死锁】。\n2. 线程安全的实现方式\n    * 互斥同步（synchronized悲观锁）:保证同一时刻只有一个线程访问共享数据，通过线程在同一个共享数据的互斥来实现线程之间的消息同步。\n        synchronized的锁对象：如果入参是对象，那么就是改对象的reference类型。没有入参，那么就是修饰的实例方法或类方法的实例对象或class对象。\n        synchronized的特性：可重入，不公平锁\n    因为访问对象或对象方法时，会获取对象的锁；如果无锁或者锁为当前线程，则锁计数器加1,，相反解锁时，计数器减1，为0时释放锁。如果获取对象锁失败，线程会阻塞等待。\n    由于计数器的存在，使得synchronized时可重入。\n    缺点：会导致线程阻塞和唤醒(切入内核态)存在性能问题\n    * 非阻塞同步（CAS乐观锁）：先操作，如果冲突再补偿。\n    **实现方式**：保证操作和冲突检测的操作是原子的，通过CAS实现。\n    CAS是CPU指令通过锁总线的方式来支持冲突检测，是直接操作CPU不需要通过操作系统也就是没有通过操作系统内核态和用户态的切换，所以效率会比互斥同步高。\n    CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该 位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前 值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”\n    **CAS的ABA问题**，通过对旧值添加版本号解决。\n    **CAS的缺点:** 循环中，获取旧值，计算新值，再回写时，比较当前值和旧值是否一致，如果冲突很严重，会导致循环一致执行，降低效率。java可通过自适应自旋锁解决。\n3. 无同步方案：数据线程私有，不需要线程之间进行同步，可实现线程安全。\n实现方式：\n    **可重入代码:** 数据均是外部传入\n    线程本地存储：ThreadLocal，线程私有ThreadLoacalMap，key为ThreadLocal<T>.threalLocalHashCode,value为线程私有的值。\n## 锁优化\n    1. 自适应自旋锁\n    利用CAS实现，根据线程上一次获取改对象的锁的成功程度进行循环次数。如果上一次成功获取对象的锁，则进行更长时间的循环。\n    如果对象的锁，很少成功获取到，直接跳过CAS。\n    2. 锁消除\n    编译期堆数据流进行分析，发现该方法或对象不可能存在竞争，则会把锁消除。\n    3. 锁粗化\n    同一个对象零碎的加锁，会把锁范围扩到整个操作序列的外部。\n    4. 轻量级锁\n        * 将对象头的MarkWord拷贝到栈帧(Lock Record)中，\n        * 然后利用CAS将MarkWord更新为指向栈帧(Lock Record), 然后标志位设为00(标识轻量锁)。**如果更新失败，先检查MarkWord是否指向当前线程，是则直接进行同步块（先设置再判断是否为本线程）。** \n        * MarkWork不是当前线程，则对象已被抢占，继续循环等待更新MarkWord，*超过2个线程竞争则升级为重量锁*\n    5. 偏向锁：如果对象被其他线程获取，则一直偏向该线程，不需要进行同步操作。\n        * 高效的原因是只需要进行一次偏向锁，访问对象时，发现是偏向锁而且指向当前线程，直接进入同步块。相比轻量锁少了一次对MarkWord进行更新的操作。\n        * 操作步骤：\n        锁对象第一次被获取时，MarkWord的标志位设为01（偏向锁），使用CAS把线程ID记录到对象的MarkWord（注意不是拷贝MarkWord到线程，再设置指针，检测是否获取锁时，直接查看对象头即可，虚拟机不需要做任何的操作）。\n        **一旦另外一个线程获取锁，理解变成无锁（01）或者升级为轻量级锁（00）**\n","tags":["java"],"categories":["java"]},{"title":"二叉树的遍历","url":"/blog/2020/06/12/binary_tree_travel/","content":"<script src=\"/js/mermaid.full.min.js\"></script>\n二叉树的遍历题型:\n1. [二叉树的前序遍历](https://leetcode-cn.com/problems/binary-tree-preorder-traversal)\n2. [二叉树的中序遍历](https://leetcode-cn.com/problems/binary-tree-inorder-traversal)\n3. [二叉树的后序遍历](https://leetcode-cn.com/problems/binary-tree-postorder-traversal)\n4.  [二叉树的层次遍历](https://leetcode-cn.com/problems/binary-tree-zigzag-level-order-traversal/)\n* [二叉树的前序遍历](https://leetcode-cn.com/problems/binary-tree-preorder-traversal)\n    前序遍历的遍历顺序: 遍历根节点->左子树->右子树。\n    遍历过程时间时遍历左右子树，根节点位置为读取数据。\n    **最左遍历法:** 前序遍历左子树在前，所以遍历是先遍历左子树，由于根节点在左子树前，所以遍历左子树的同时，需要获取节点；直到遍历到左子树的叶节点，再遍历右子树【右子树的遍历也是先遍历完右子树的左子树】。\n    遍历过程如图所示。\n![二叉树的前序遍历](https://github.com/hezhuhui/gallery/raw/master/leetcode/preorder.jpg)\n大致过程为:\n   1. 从根节点一直入栈，压到最左侧叶节点，节点压入栈的过程同时获取节点到ans数组。\n   2. 到左侧叶子节点后，切换右子树，再重复步骤1。\n   3. 直到压到右子树最后一个阶段。\n   4. 最后输出的ans即为前序遍历的结果。\n    代码如下:\n    \n```\n public List<Integer> preorderTraversal(TreeNode root) {\n        if(root == null){\n            return new ArrayList<>();\n        }\n        Stack<TreeNode> stack = new Stack<>();\n        LinkedList<Integer> ans = new LinkedList<>();\n        while(!stack.isEmpty() || root != null){\n            //左子树一直入栈，压到左叶子节点为止\n            while(root != null){\n                stack.push(root); //节点入栈\n                ans.add(root.val); //节点写入ans\n                root = root.left; // 切换到左子树\n            }\n            //到达左叶子节点，切换到右子树\n            root = stack.pop();\n            root = root.right;\n        }\n        return ans;\n    }\n\n\n```\n* [二叉树的中序遍历](https://leetcode-cn.com/problems/binary-tree-inorder-traversal)\n中序遍历的顺序为:左子树->根节点->右子树，二叉树搜索树根据使用中序遍历，可以从小到大输出有序数组。\n 中序遍历遍历的数据的方式[最左遍历法]可以与前序遍历的方式一致，但是由于根节点输出位置在左子树之后。所有输出的根节点需要在出栈的过程。即左子树的左叶子最先直接输出。\n 遍历和输出过程如图所示:\n \n![二叉树的中序遍历](\nhttps://github.com/hezhuhui/gallery/raw/master/leetcode/inorder.jpg)\n 注意遍历方式与前序遍历一致，但是输出节点到ans的时机变为出栈时。\n ````\n  public List<Integer> inorderTraversal(TreeNode root) {\n         if(root == null){\n            return new ArrayList<>();\n        }\n        Stack<TreeNode> stack = new Stack<>();\n        List<Integer> ans = new ArrayList<>();\n        while(!stack.isEmpty() || root != null){\n            //先将最左压倒底\n            while(root != null){\n                stack.push(root);\n                root = root.left;\n            }\n            //切换到右子树\n            root = stack.pop();\n            ans.add(root.val); //输出答案时机为出栈时\n            root = root.right;\n        }\n        return ans;\n    }\n````\n* [二叉树的后序遍历](https://leetcode-cn.com/problems/binary-tree-postorder-traversal)\n后序遍历的遍历顺序为左子树->右子树->根节点，输出结果刚好与前序遍历相反。\n **最右遍历法:** 根节点需要在右子树之后，也就是可以通过先将右子树的右侧全部入栈，同时逆序排列，即可得到结果。\n遍历过程如图所示。\n![二叉树的后序遍历](\nhttps://github.com/hezhuhui/gallery/raw/master/leetcode/postorder.jpg)\n图中，先遍历右子树，且遍历过程中将节点输入到数组中，但是最后的结果需要逆序输出。也就是输出的结果为 4 5 2 1 6 2 1[序号的逆序输出] \n实现代码如下:\n```\n public List<Integer> postorderTraversal(TreeNode root) {\n        if(root == null){\n            return new ArrayList<>();\n        }\n        Stack<TreeNode> stack = new Stack<>();\n        LinkedList<Integer> ans = new LinkedList<>();\n        while(!stack.isEmpty() || root != null){\n            //遍历右子树，同时逆序排到输出结果中。\n            while(root != null){\n                stack.push(root);\n                ans.addFirst(root.val);\n                root = root.right;\n            }\n            //最右侧节点为叶子节点后，切到左子树\n            root = stack.pop();\n            root = root.left;\n        }\n        return ans;\n    }\n```\n综上: 二叉树的前中后遍历可以总结为两种方法，最左和最右遍历法。其中中序遍历同时适用最左和最右遍历法。\n所以前中后遍历二叉树关键是定义好两点:\n1、使用的遍历的方法:最左/最右。\n2、输出节点的时机。 \n3、输出的结果是否需要逆序。\n通用代码模板如下:\n```\n public List<Integer> inorderTraversal(TreeNode root) {\n         //base case\n         if(root == null){\n            return new ArrayList<>();\n        }\n        Stack<TreeNode> stack = new Stack<>();\n        List<Integer> ans = new ArrayList<>();\n        while(!stack.isEmpty() || root != null){\n            //先将最左/最右压到叶子节点\n            while(root != null){\n                stack.push(root);\n                //输出时机\n                //如果是前序遍历使用最左输出，根节点位于左子树之前，所示先输出节点\n                //如果中序遍历适用最左遍历，由于根节点位于左子树之后所以不能输出结果\n                //如果后序遍历使用最右遍历，根节点位于右子树之后【理应先输出根节点】，由于逆序输出，变成了根节点可以先与右子树输出，所以此处需要输出节点\n                //最左/最右输出，\n                //如果是最左输出，需要节点一直为左子树根节点 root = root.left;\n                //如果是最右输出，需要节点一直为右子树根节点 root = root.right;\n            }\n            //切换到右子树\n            root = stack.pop();\n            //输出时机\n            //根节点位于最左/最右之后，在此输出。因为可以形成从叶节点开始输出结果，得到先输出最左/最右的效果\n            // ans.add(root.val); //输出答案时机为出栈时\n           //切换时机\n           //如果是最左，在此切换为右子树；如果是最右，则刚好相反\n           root = root.right;\n        }\n        return ans;\n    }\n```\n* 层次遍历 [102](https://leetcode-cn.com/problems/binary-tree-level-order-traversal/submissions/) [103](https://leetcode-cn.com/problems/binary-tree-zigzag-level-order-traversal/) [429](https://leetcode-cn.com/problems/n-ary-tree-level-order-traversal/)\n层次遍历与前中后序遍历不一样，本质上来说层次遍历是一种bfs，前中后遍历是一种dfs。dfs二叉树是往往是后进先出，即出栈一般是叶节点先出栈，再到非叶子节点直到树的根节点。然而bfs不同的是遍历需要从根节点开始，输出也是从根节点开始，所以是先进先出，所以一般使用队列来实现bfs。\n二叉树的层次遍历代码模板:\n```\npublic List<List<Integer>> levelOrder(TreeNode root) {\n        List<List<Integer>> ans = new ArrayList<>();\n        if(root == null){\n            return ans;\n        }\n        Queue<TreeNode> queue = new LinkedList<>();\n        queue.offer(root);\n        while(!queue.isEmpty()){\n            //遍历一层的元素\n            List<Integer> list = new ArrayList<>();\n            int len = queue.size();\n            //按层输出\n            for(int i = 0; i < len; i++){\n                   // 每一层元素的出队队和入队的方向决定了层次遍历的规则\n                   // 如果需要按照Z输出，需要添加判断条件，使得每一层入队和出队在队列的方向是相反的。\n                   //同时注意，入队处不能作为出队处，否则会导致下一层的数据提前出队。\n                   // 也就是入队和出队在同一处，会导致刚入队的数据[理应是下一层的数据]，就会立马出队，违反了先进先出原则。\n                TreeNode node = queue.poll();\n                if(node.left != null){\n                    queue.offer(node.left);\n                }\n                if(node.right != null){\n                    queue.offer(node.right);\n                }\n                 list.add(node.val);\n            }\n            ans.add(list);\n        }\n        return ans;\n    }\n```\n","tags":["数据结构与算法"],"categories":["数据结构与算法"]},{"title":"二叉树视图/节点求和问题","url":"/blog/2020/05/01/binary_tree_view/","content":"<script src=\"/js/mermaid.full.min.js\"></script>\n## 问题分类\n* 左视图/右视图节点问题:求和/列出节点值\n* 左节点/右叶子节点问题:求和/列出节点值\n* 俯视图\n## 求解技巧\n1. 左/右视图问题（以右视图为例：[二叉树的右视图](https://leetcode-cn.com/problems/binary-tree-right-side-view/)）\n* 问题描述: 以右视图为例，想象自己站在它的右侧，按照从顶部到底部的顺序，返回从右侧所能看到的节点值。\n* 分析：\n<u>本质求二叉树每一层的最右边的节点</u>，可以使用bfs对二叉树进行从左到右层次遍历，取每一层最右边的节点加入列表。\n* 代码实现\n 通过层次遍历获取每一层数据的通用模板\n```\n  public T readTree(TreeNode root) {\n        // base case\n        List<Integer> ans = new ArrayList<>();\n        if(root == null){\n            return T;\n        }\n        // 定义bfs使用的队列\n        Queue<TreeNode> queue = new LinkedList<>();\n        // 先加入根节点\n        queue.offer(root);\n        while (!queue.isEmpty()){\n            // 求每一层节点的个数\n            int size = queue.size();\n            // 遍历每一层的节点\n            for(int i = 0; i < size; i++){\n                TreeNode tmp = queue.poll();\n                /**\n                * 此处实现每一层的数据操作\n                * 以右视图为例，此处可添加代码\n                *  \n                    // 每一层最右边的节点加入结果集合\n                   if(i == size - 1){\n                    ans.add(tmp.val);\n                }\n                **/\n                //添加下一层数据到队列，从左往右添加\n                if(tmp.left != null){\n                    queue.offer(tmp.left);\n                }\n                if(tmp.right != null){\n                    queue.offer(tmp.right);\n                }\n            }\n        }\n        return T;\n    }\n\n```\n\n2. 左节点/右叶子节点问题：[左叶子之和](https://leetcode-cn.com/problems/sum-of-left-leaves/)\n* 问题描述: 以求左叶子为例，题目要求获取所有左子树的叶子节点之和，不包含非叶子节点。\n* 分析: 注意与左视图问题区别：问题可以转化为求所有叶子节点中，左叶子之和。如果使用bfs，由于是层次遍历会导致左右子树的属性丢失，所有使用dfs遍历左子树和右子树，同时标记当前遍历处于哪个子树（通过参数标识）。\n* 代码实现\n```\n\nclass Solution {\n    int sum = 0;\n    public int sumOfLeftLeaves(TreeNode root) {\n        if(root == null) {\n            return 0;\n        }\n        if(root.left != null){\n            dfs(root.left,true);\n        }\n        if(root.right != null){\n            dfs(root.right,false);\n        }\n        return sum;\n    }\n    void dfs(TreeNode root,Boolean isLeft){\n        // 该节点为叶子节点并且是左节点\n        if(root.left == null && root.right == null && isLeft){\n            sum += root.val;\n        }\n        if(root.left != null){\n            dfs(root.left,true);\n        }\n        if(root.right != null){\n            dfs(root.right,false);\n        }\n    }\n}\n```\n\n3. 俯视图\n* 问题描述:想象自身从二叉树的上方俯视二叉树，以根节点为界，列出根节点右侧的节点。\n* 分析:\n   1. 从俯视图右侧的看到的节点，不一定为右子树节点，因为如果根节点的右子树为null，但是左子树一直往右偏移，可能越过根节点的正下方，从而出现在俯视图的根节点右侧。\n   2. 每一层的最右节点不一定为俯视图看到节点，因为如果上层的最右节点挡住了当前层的节点也就看不到当前节点了。\n   3. 根据以上分析，关键点：**记录每一个节点相对于root节点的偏移量a，再根据偏移量a与当前结果数组大小比较，判断当前节点偏移量是否大于数组大小，如果大于表示当前节点偏移量不会被遮挡，否则会被遮挡。**\n   4. 由于偏移量a的获取，需要根据上一层偏移量的大小确定，也就是**依赖纵向关系，所以使用dfs不能使用bfs**。\n  \n * 代码实现\n ```\nclass Solution {\n    List<Integer> ans = new ArrayList<>();\n    public List<Integer> rightSideView(TreeNode root) {\n        if(root == null){\n            return new ArrayList<>();\n        }\n        ans.add(root.val);\n        if(root.left != null){\n            dfs(root.left,  -1);\n        }\n        if(root.right != null ){\n            dfs(root.right,  1);\n        }\n        return ans;\n    }\n    //index为偏移量，向左偏移量-1，向右+1\n    void dfs(TreeNode root, int index){\n    // 当节点不为null，且不阻挡时，加入结果集合\n        if(root != null && index >= ans.size()){\n            ans.add(root.val);\n        }\n        if(root.left != null){\n            dfs(root.left, index - 1);\n        }\n        if(root.right != null ){\n            dfs(root.right, index + 1);\n        }\n    }\n}\n```\n## 总结\n1.bfs和dfs遍历二叉树的使用场景:\n* **如果当前节点的属性依赖上一节点传递，则使用dfs**。如需要依赖上一节点来确定当前节点是左节点/右节点或者节点相对根节点偏移量。\n* **如果当前节点的属性依赖兄弟节点传递，则使用bfs**。如需要确定当前节点位于该层的位置。\n","tags":["数据结构与算法"],"categories":["数据结构与算法"]},{"title":"滑动窗口解法","url":"/blog/2020/04/06/slide_window/","content":"<script src=\"/js/mermaid.full.min.js\"></script>\n## 线程安全\n1. 线程安全概念：不管运行环境的调度或交替进行，最终的运行结果都是正确的。\n共享数据的线程安全从强到弱的分类：\n    * 不可变性：对象被构造出来后，内部的状态不会改变。基本数据类型；普通对象不会改变，或者状态被final修饰，如String，枚举类\n    * 绝对安全：不管运行环境如何，调用者不需要做额外的措施保护线程安全。\n    * 相对安全：一般意义上说的线程安全，对对象的单独操作是线程安全的。如线程安全类HashTable，Vector（不是任意环境下线程安全，利用多线程同时查询和删除，会出现线程不安全，需要额外的措施保证线程安全）\n    * 线程兼容：对象本身线程不安全，通过额外的措施可以保证线程安全。\n    * 线程对立: 无论使用任何措施都不能保证线程安全，例如suspend()和resume()【都不会释放锁，可能导致死锁】。\n2. 线程安全的实现方式\n    * 互斥同步（synchronized悲观锁）:保证同一时刻只有一个线程访问共享数据，通过线程在同一个共享数据的互斥来实现线程之间的消息同步。\n        synchronized的锁对象：如果入参是对象，那么就是改对象的reference类型。没有入参，那么就是修饰的实例方法或类方法的实例对象或class对象。\n        synchronized的特性：可重入，不公平锁\n    因为访问对象或对象方法时，会获取对象的锁；如果无锁或者锁为当前线程，则锁计数器加1,，相反解锁时，计数器减1，为0时释放锁。如果获取对象锁失败，线程会阻塞等待。\n    由于计数器的存在，使得synchronized时可重入。\n    缺点：会导致线程阻塞和唤醒(切入内核态)存在性能问题\n    * 非阻塞同步（CAS乐观锁）：先操作，如果冲突再补偿。\n    **实现方式**：保证操作和冲突检测的操作是原子的，通过CAS实现。\n    CAS是CPU指令通过锁总线的方式来支持冲突检测，是直接操作CPU不需要通过操作系统也就是没有通过操作系统内核态和用户态的切换，所以效率会比互斥同步高。\n    CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该 位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前 值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”\n    **CAS的ABA问题**，通过对旧值添加版本号解决。\n    **CAS的缺点:** 循环中，获取旧值，计算新值，再回写时，比较当前值和旧值是否一致，如果冲突很严重，会导致循环一致执行，降低效率。java可通过自适应自旋锁解决。\n3. 无同步方案：数据线程私有，不需要线程之间进行同步，可实现线程安全。\n实现方式：\n    **可重入代码:** 数据均是外部传入\n    线程本地存储：ThreadLocal，线程私有ThreadLoacalMap，key为ThreadLocal<T>.threalLocalHashCode,value为线程私有的值。\n## 锁优化\n    1. 自适应自旋锁\n    利用CAS实现，根据线程上一次获取改对象的锁的成功程度进行循环次数。如果上一次成功获取对象的锁，则进行更长时间的循环。\n    如果对象的锁，很少成功获取到，直接跳过CAS。\n    2. 锁消除\n    编译期堆数据流进行分析，发现该方法或对象不可能存在竞争，则会把锁消除。\n    3. 锁粗化\n    同一个对象零碎的加锁，会把锁范围扩到整个操作序列的外部。\n    4. 轻量级锁\n        * 将对象头的MarkWord拷贝到栈帧(Lock Record)中，\n        * 然后利用CAS将MarkWord更新为指向栈帧(Lock Record), 然后标志位设为00(标识轻量锁)。**如果更新失败，先检查MarkWord是否指向当前线程，是则直接进行同步块（先设置再判断是否为本线程）。** \n        * MarkWork不是当前线程，则对象已被抢占，继续循环等待更新MarkWord，*超过2个线程竞争则升级为重量锁*\n    5. 偏向锁：如果对象被其他线程获取，则一直偏向该线程，不需要进行同步操作。\n        * 高效的原因是只需要进行一次偏向锁，访问对象时，发现是偏向锁而且指向当前线程，直接进入同步块。相比轻量锁少了一次对MarkWord进行更新的操作。\n        * 操作步骤：\n        锁对象第一次被获取时，MarkWord的标志位设为01（偏向锁），使用CAS把线程ID记录到对象的MarkWord（注意不是拷贝MarkWord到线程，再设置指针，检测是否获取锁时，直接查看对象头即可，虚拟机不需要做任何的操作）。\n        **一旦另外一个线程获取锁，理解变成无锁（01）或者升级为轻量级锁（00）**\n","tags":["数据结构与算法"],"categories":["数据结构与算法"]}]